{

# general inputs

'env_name'      :   'hopper-medium-v2',
'act_repeat'    :   1,
'seed'          :   123,
'num_iter'      :   1,
'eval_rollouts' :   10,
'num_models'    :   5,
'save_freq'     :   25,
'device'        :   'cuda',
'learn_reward'  :   False,
'reward_file'   :   './utils/reward_functions/gym_hopper.py',
'pessimism_coef':   10.0,  # 10.0
'context_dim'   :    0,
#'truncate_reward' : 0.0,
'exp_notes'     :   'Example to illustrate MOReL on a D4RL task.',

#behavior cloning
'bc_epochs'     : 20,
'bc_batch_size' : 256,
'bc_lr'         : 1e-3,

# dynamics learning

'hidden_size'   :   (512, 512),
'activation'    :   'relu',
'fit_lr'        :   1e-3,
'fit_wd'        :   0.0,
'fit_mb_size'   :   256,
'fit_epochs'    :   25,
'refresh_fit'   :   False,
'max_steps'     :   1e8,
'no_o_whitening':   True,
'slackness'     :   0.1,
'checkpoint_freq' : 1,

# NPG params

'policy_size'   :   (256, 256),
'step_size'     :   0.02,
'init_log_std'  :   -0.25,
'min_log_std'   :   -1.0,
'gamma'         :   0.999,
'gae_lambda'    :   0.97,
'update_paths'  :   50,
'start_state'   :   'init',
'horizon'       :   700,
'npg_hp'        :   dict(FIM_invert_args={'iters': 20, 'damping': 1e-3}),

#Value function params
'val_fn_size': (512, 512),
'val_fn_lr': 1e-3,
'val_fn_wd': 0.0,
'val_fn_epochs': 20,
'val_fn_batch_size': 256,


# MPC Params
'mpc_params': {
'n_iters': 1,
'horizon': 20,
'num_particles': 100,
#'init_cov': 0.001, # 0.001
'init_std': 0.1,
#'init_mean':
'gamma': 0.999,
'beta': 3.33, # 1.0 #3.33,
'mixing_factor': 0.2, #0.4, #0.8, #0.6,
'td_lam': 0.97,
'step_size_mean': 1.0,
'sample_mode': 'best_mean',
'base_action': 'repeat',
'hotstart': True,
'shift_steps': 1,
'squash_fn': 'clamp',
'optimize_open_loop': True, # False, True
'pessimism_mode': 'atac3', #'bonus', # truncation, bonus, discount
'epsilon': 1.0,
'filter_coeffs': [0.2, 0.8, 0.0],
'sync_model_randomness': True,

}





}
